# MSME Credit Scoring - Technical Documentation

## ğŸ“š Documentation Index

This folder contains comprehensive technical documentation for the MSME Credit Scoring model training pipeline.

---

## Documents

### 1. [LIGHTGBM_DEEP_DIVE.md](./LIGHTGBM_DEEP_DIVE.md)
**Full Algorithm Explanation**

Learn how LightGBM works under the hood:
- âœ… Gradient Boosting fundamentals
- âœ… Histogram-based data splitting (255 bins)
- âœ… Leaf-wise (best-first) tree growth
- âœ… Exclusive Feature Bundling (EFB)
- âœ… Gradient-based One-Side Sampling (GOSS)
- âœ… Mathematical formulations
- âœ… Why LightGBM is perfect for credit scoring

---

### 2. [TRAINING_FLOW.md](./TRAINING_FLOW.md)
**Step-by-Step Code Walkthrough**

Understand exactly what happens when you run training:
- âœ… Entry point and argument parsing
- âœ… Data loading from CSV
- âœ… Time-based train/val/test splitting
- âœ… Preprocessing pipeline (clip, impute, encode, engineer)
- âœ… Optuna hyperparameter tuning
- âœ… LightGBM training loop
- âœ… Probability calibration
- âœ… SHAP explainability initialization
- âœ… Model evaluation and metrics
- âœ… Artifact saving

---

### 3. [HYPERPARAMETERS_GUIDE.md](./HYPERPARAMETERS_GUIDE.md)
**Complete Parameter Reference**

Every hyperparameter explained:
- âœ… Objective & metric parameters
- âœ… Tree structure (num_leaves, max_depth, min_child_samples)
- âœ… Learning parameters (learning_rate, n_estimators)
- âœ… Regularization (reg_alpha, reg_lambda)
- âœ… Sampling (feature_fraction, bagging_fraction)
- âœ… Class imbalance handling (scale_pos_weight)
- âœ… Training control (early_stopping)
- âœ… Tuning recommendations

---

## Quick Start

### Running Training

```bash
# Basic training with default parameters
python train.py

# Training with custom data and hyperparameter tuning
python train.py --data msme_comprehensive_training_data.csv --tune --trials 30

# Full options
python train.py \
    --data msme_comprehensive_training_data.csv \
    --output msme_model_artifacts \
    --samples 25000 \
    --tune \
    --trials 50
```

### Generating Synthetic Data

```bash
python generate_comprehensive_data.py
```

This creates `msme_comprehensive_training_data.csv` with:
- 10,200 samples
- All risk levels (very low â†’ very high)
- 7 edge case scenarios

---

## Model Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MSME CREDIT SCORING PIPELINE                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚    INPUT    â”‚â”€â”€â”€â”€â–¶â”‚ PREPROCESSOR â”‚â”€â”€â”€â”€â–¶â”‚  LIGHTGBM   â”‚       â”‚
â”‚   â”‚  92 Featuresâ”‚     â”‚ Clip/Impute/ â”‚     â”‚   12 Trees  â”‚       â”‚
â”‚   â”‚             â”‚     â”‚ Encode/Eng.  â”‚     â”‚  (boosted)  â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                   â”‚               â”‚
â”‚                                                   â–¼               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚   OUTPUT    â”‚â—€â”€â”€â”€â”€â”‚  BLENDING   â”‚â—€â”€â”€â”€â”€â”‚ CALIBRATOR  â”‚       â”‚
â”‚   â”‚ Score: 544  â”‚     â”‚ GBM + Segmentâ”‚     â”‚  Isotonic   â”‚       â”‚
â”‚   â”‚ Risk: High  â”‚     â”‚  Subscores  â”‚     â”‚ Regression  â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Files

| File | Purpose |
|------|---------|
| `train.py` | Model training pipeline |
| `score.py` | Scoring functions and weights |
| `data_prep.py` | Data preprocessing |
| `app.py` | FastAPI scoring endpoint |
| `generate_comprehensive_data.py` | Synthetic data generator |

---

## Performance Summary

| Metric | Value |
|--------|-------|
| Validation AUC | 0.8022 |
| Test AUC | 0.7252 |
| KS Statistic | 0.3582 |
| Default Rate | 9.25% |
| Features | 92 |
| Final Trees | 12 |

### Risk Bucket Separation

| Score Range | Risk Level | Default Rate |
|-------------|------------|--------------|
| 750-900 | Very Low | 2.7% |
| 650-749 | Low | - |
| 550-649 | Medium | 7.4% |
| 450-549 | High | 15.3% |
| 300-449 | Very High | 25.2% |

---

## Need Help?

1. **Understanding the algorithm?** â†’ Read [LIGHTGBM_DEEP_DIVE.md](./LIGHTGBM_DEEP_DIVE.md)
2. **Following the code?** â†’ Read [TRAINING_FLOW.md](./TRAINING_FLOW.md)
3. **Tuning parameters?** â†’ Read [HYPERPARAMETERS_GUIDE.md](./HYPERPARAMETERS_GUIDE.md)

---

*Last updated: January 2026*



